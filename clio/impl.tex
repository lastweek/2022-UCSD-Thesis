\section{\sys\ Implementation}
\label{sec:clio:impl}

Apart from challenges discussed in \S\ref{sec:clio:design}, our implementation of \sys\ also needs to overcome several practical challenges, for example, how can different hardware components most efficiently work together in \sysboard, how to minimize software overhead in \syslib. 
This section describes how we implemented \sysboard\ and \syslib, focusing on the new techniques we designed to overcome these challenges.
Currently, \sys\ consists of 24.6K SLOC (excluding computation offloads and third-party IPs).
They include 5.6K SLOC in SpinalHDL~\cite{SpinalHDL} and 2K in C HLS for FPGA hardware, and 17K in C for \syslib\ and ARM software.
We use vendor-supplied interconnect and DDR IPs, and an open-source MAC and PHY network stack~\cite{Corundum-FCCM20}.

\ulinebfpara{\sysboard\ Prototyping.}~~
We prototyped \sysboard\ with a low-cost (\$2495 retail price) Xilinx MPSoC board~\cite{ZCU106} and build the hardware fast path (which is anticipated to be built in ASIC) with FPGA.
All \sys's FPGA modules run at 250\,MHz clock frequency and 512-bit data width.
They all %(network, pre-processor, core memory) are able to 
achieve an {\em Initiation Interval} ({\em II}) of one
(II is the number of clock cycles between the start time
of consecutive loop iterations, and it decides the maximum
achievable bandwidth). Achieving II of one is not easy and
requires careful pipeline design in all the modules. With II one, our data path can
achieve a maximum of 128\Gbps\ throughput even with just the slower FPGA clock frequency and would be higher with real ASIC implementation.

Our prototyping board consists of a small FPGA with 504K logic cells (LUTs) and 4.75\MB\ FPGA memory (BRAM),
a quad-core ARM Cortex-A53 processor,
two 10\Gbps\ SFP+ ports connected to the FPGA, 
and 2\GB\ of off-chip on-board memory.
This board has several differences from our anticipated real \sysboard:
its network port bandwidth and on-board memory size are both much lower than our target,
and like all FPGA prototypes, its clock frequency is much lower than real ASIC.
Unfortunately, no board on the market offers the combination of small FPGA/ARM (required for low cost) 
and large memory and high-speed network ports. %high-speed network and/or large amounts of on-board DRAM with small processing units,
%but building one only requires board-level changes.

Nonetheless, certain features of this board are likely to exist in a real \sysboard,
and these features guide our implementation.
Its ARM processor and the FPGA connect through an interconnect that has high bandwidth (90\GB/s) but high delay (40\mus).
Although better interconnects could be built, crossing ARM and FPGA would inevitably incur non-trivial latency.
%that allows the FPGA to perform DMA operations to 
%ARM's local memory (the ARM has \fixme{XXX} local DRAM). % (\fixme{XXX} RTT and \fixme{XXX} bandwidth).
With this board, the ARM's access to on-board DRAM is much slower than the FPGA's access because the ARM has to first physically cross the FPGA then to the DRAM.
%We envision each board to host 100\GB{}s of DRAM.
%the physical connection between software cores and ASIC/FPGA is likely to continue having high bandwidth but non-trivial delay,
A better design would connect the ARM directly to the DRAM, 
but it will still be slower for the ARM to access on-board DRAM than its local on-chip memory.

To mitigate the problem of slow accesses to on-board DRAM from ARM,
we maintain shadow copies of metadata at ARM's local DRAM.
%to avoid the much higher (79\x\ in our experiment) cost of going to the on-board DRAM.
For example, we store a {\em shadow} version of the page table in ARM's local memory,
so that the control path can read page table content faster.
When the control path needs to perform a virtual memory space allocation, it reads the shadow page table to test if an address would cause an overflow (\S\ref{sec:clio:addr-trans}).
We keep the shadow page table in sync with the real page table by updating both tables when adding, removing, or updating the page table entries.
%
%first, we shift operations involving ARM off the performance-critical path.

In addition to maintaining shadow metadata, we employ an efficient polling mechanism for ARM/FPGA communication.
We dedicate one ARM core to busy poll an RX ring buffer between ARM and FPGA,
where the FPGA posts tasks for ARM.
This polling thread hands over tasks to other worker threads for task handling %that perform the tasks
and post responses to a TX ring buffer.
%We use DMA to implement the ring buffers, 
%as DMA is the fastest communication methods we found among all the available ones.

%matching future high-bandwidth networks.
\sysboard's network stack builds on top of standard, vendor-supplied Ethernet physical and link-layer IPs, with just an additional thin checksum-verify and ack-generation layer on top.
This layer uses much fewer resources compared to a normal RDMA-like stack (\S\ref{sec:clio:results-cost}).
%
We use lossless Ethernet with Priority Flow Control (PFC) for less packet loss and retransmission. Since PFC has issues like head-of-line blocking~\cite{DCQCN-sigcomm15,hpcc-sigcomm19,alibaba-rdma-nsdi21,IRN}, we rely on our congestion and incast control to avoid triggering PFC as much as possible.

Finally, to assist \sys\ users in building their applications, we implemented a simple software simulator
of \sysboard\ which works with \syslib\ for developers to test their code without the need to run an actual \sysboard.

\ulinebfpara{\syslib\ Implementation.}~~
Even though we optimize the performance of \sysboard, the end-to-end application performance can still be hugely impacted if the host software component (\syslib) is not as fast.
Thus, our \syslib\ implementation aims to provide low-latency performance by adopting several ideas (e.g., data inlining, doorbell batching) from recent low-latency I/O solutions~\cite{ERPC,Kalia14-RDMAKV,Kalia16-ATC,Tsai17-SOSP,Shinjuku,Shenango,demikernel-sosp21}.
We implemented \syslib\ in the user space. 
It has three parts: a user-facing request ordering layer that performs dependency check and ordering of address-conflicting requests,
a transport layer that performs congestion/incast control and request-level retransmission, 
and a low-level device driver layer that interacts with the NIC (similar to DPDK~\cite{DPDK} but simpler).
\syslib\ bypasses kernel and directly issues raw Ethernet requests to the NIC with zero memory copy.
%The transport layer implements our core logic. The shim layer is similar to DPDK but much simplified and customized for our own usage. 
%We use per-thread inline polling.
For synchronous APIs, we let the requesting thread poll the NIC for receiving the response right after each request.
For asynchronous APIs, the application thread proceeds with other computations after issuing the request and only busy polls when the program calls \poll.